01. Data Collection and Preprocessing :

# Assuming you have a CSV file 'legal_documents.csv' with 'text' and 'category' columns
import pandas as pd

# Load the dataset
data = pd.read_csv('legal_documents.csv')

# Preprocessing: cleaning and tokenization (you might want to use regex, remove stopwords, etc.)
# Example:
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

def preprocess_text(text):
    # Remove non-alphanumeric characters and convert to lowercase
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text.lower())
    # Tokenize the text
    tokens = word_tokenize(text)
    # Remove stopwords
    tokens = [token for token in tokens if token not in stopwords.words('english')]
    # Join tokens back into text
    return ' '.join(tokens)

data['cleaned_text'] = data['text'].apply(preprocess_text)

02. Machine Learning Model Development

from sklearn.svm import SVC

# Initialize SVM model
svm_model = SVC(kernel='linear')

# Train the model
svm_model.fit(X_train_tfidf, y_train)


03.Plagiarism Detection Integration:

from sklearn.metrics.pairwise import cosine_similarity

# Calculate cosine similarity between documents
cos_sim = cosine_similarity(X_train_tfidf)

# You'll need to define a threshold to determine if a document is plagiarized or not
threshold = 0.8  # Example threshold value

# Example function to check for plagiarism
def check_plagiarism(doc_index):
    similar_docs_indices = [i for i, sim in enumerate(cos_sim[doc_index]) if sim > threshold]
    return similar_docs_indices

# Example usage
plagiarized_docs_indices = check_plagiarism(0)  # Check for plagiarism in the first document

04. Performance Evaluation:

from sklearn.metrics import classification_report

# Evaluate classification performance on test set
y_pred = svm_model.predict(X_test_tfidf)
print(classification_report(y_test, y_pred))
